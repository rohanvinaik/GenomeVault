from typing import Any, Dict

# mypy: allow-untyped-defs
import torch

class MyAutogradFunction(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x) -> None:
            """TODO: Add docstring for forward"""
    return x.clone()

    @staticmethod
    def backward(ctx, grad_output) -> None:
            """TODO: Add docstring for backward"""
    return grad_output + 1

class AutogradFunction(torch.nn.Module):
    """
    TorchDynamo does not keep track of backward() on autograd functions. We recommend to
    use `allow_in_graph` to mitigate this problem.
    """

    def forward(self, x) -> None:
            """TODO: Add docstring for forward"""
    return MyAutogradFunction.apply(x)

example_args = (torch.randn(3, 2),)
model = AutogradFunction()
