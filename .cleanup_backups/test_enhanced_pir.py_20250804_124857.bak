"""
Comprehensive tests for enhanced PIR implementation.
"""

import asyncio
import json
import struct

import numpy as np
import pytest

from genomevault.pir.server.enhanced_pir_server import (EnhancedPIRServer,
                                                        GenomicRegion,
                                                        OptimizedPIRDatabase,
                                                        ShardMetadata,
                                                        TrustedSignatoryServer)


class TestOptimizedPIRDatabase:
    """Test optimized PIR database functionality."""

    @pytest.fixture
    def database(self, tmp_path):
        """Create test database instance."""
        return OptimizedPIRDatabase(tmp_path, cache_size_mb=10)

    @pytest.fixture
    def test_shard(self, tmp_path):
        """Create test shard with index."""
        # Create data file
        data_path = tmp_path / "test_shard.dat"
        index_path = tmp_path / "test_shard.idx"

        # Write test data
        with open(data_path, "wb") as f:
            # Write 10 test items
            for i in range(10):
                data = b"item_{i}" * 10  # Make it longer
                f.write(struct.pack(">H", len(data)))  # Size
                f.write(data)

        # Write index
        with open(index_path, "wb") as f:
            offset = 0
            for i in range(10):
                # chr(1 byte), position(4 bytes), offset(4 bytes)
                f.write(struct.pack("B", 1))  # chr1
                f.write(struct.pack(">I", i * 1000000))  # position
                f.write(struct.pack(">I", offset))  # data offset

                # Calculate next offset
                item_size = len(b"item_{i}" * 10) + 2  # +2 for size header
                offset += item_size

        return ShardMetadata(
            shard_id="test_shard",
            data_path=data_path,
            index_path=index_path,
            size=data_path.stat().st_size,
            item_count=10,
            data_type="genomic",
            version="1.0",
            checksum="",
            chromosome_ranges={"chr1": (0, 10000000)},
        )

    @pytest.mark.asyncio
    async def test_load_shard_index(self, database, test_shard):
        """Test loading shard index."""
        index = await database.load_shard_index(test_shard)

        assert len(index) == 10
        assert "chr1:0" in index
        assert "chr1:9000000" in index
        assert index["chr1:0"] == 0

    @pytest.mark.asyncio
    async def test_query_item(self, database, test_shard):
        """Test querying specific item."""
        # Query existing item
        data = await database.query_item(test_shard, "chr1:1000000")
        assert data is not None
        assert b"item_1" in data

        # Query non-existent item
        data = await database.query_item(test_shard, "chr2:1000000")
        assert data is None

    def test_cache_functionality(self, database, test_shard):
        """Test caching behavior."""
        # Simulate cache updates
        for i in range(20):
            key = "test_key_{i}"
            data = b"test_data_{i}"
            database._update_cache(key, data)

        # Check cache stats
        stats = database.get_cache_stats()
        assert stats["cache_size"] > 0

        # Verify LRU eviction happened
        assert stats["cache_size"] <= 20


class TestEnhancedPIRServer:
    """Test enhanced PIR server functionality."""

    @pytest.fixture
    async def server(self, tmp_path):
        """Create test server instance."""
        # Create minimal shard structure
        manifest = {
            "shards": [
                {
                    "id": "genomic_chr1",
                    "data_file": "chr1.dat",
                    "index_file": "chr1.idx",
                    "size": 1000000,
                    "item_count": 1000,
                    "data_type": "genomic",
                    "version": "1.0",
                    "checksum": "abc123",
                    "chromosome_ranges": {"chr1": [0, 250000000]},
                }
            ]
        }

        manifest_path = tmp_path / "enhanced_manifest.json"
        with open(manifest_path, "w") as f:
            json.dump(manifest, f)

        # Create dummy data files
        (tmp_path / "chr1.dat").touch()
        (tmp_path / "chr1.idx").touch()

        server = EnhancedPIRServer(
            server_id="test_server",
            data_directory=tmp_path,
            is_trusted_signatory=False,
            enable_preprocessing=True,
            cache_size_mb=100,
        )

        yield server
        await server.shutdown()

    def test_server_initialization(self, tmp_path):
        """Test server initialization."""
        server = EnhancedPIRServer(
            server_id="test_001", data_directory=tmp_path, is_trusted_signatory=True
        )

        assert server.server_id == "test_001"
        assert server.is_trusted_signatory
        assert server.enable_preprocessing

    @pytest.mark.asyncio
    async def test_process_query(self, server):
        """Test query processing."""
        query = {
            "query_id": "test_query_001",
            "client_id": "client_123",
            "query_vectors": [
                np.zeros(1000, dtype=np.uint8)
            ],  # All zeros for simplicity
            "query_type": "genomic",
            "parameters": {"regions": [{"chromosome": "chr1", "position": 1000000}]},
        }

        # Set one position to select
        query["query_vectors"][0][10] = 1

        response = await server.process_query(query)

        assert response["query_id"] == "test_query_001"
        assert response["server_id"] == "test_server"
        assert "processing_time_ms" in response
        assert "results" in response
        assert len(response["results"]) == 1

    @pytest.mark.asyncio
    async def test_rate_limiting(self, server):
        """Test rate limiting functionality."""
        # Simulate many requests from same client
        client_id = "aggressive_client"

        # First 100 requests should succeed
        for i in range(100):
            assert server._check_rate_limit(client_id)

        # 101st request should fail
        assert not server._check_rate_limit(client_id)

    @pytest.mark.asyncio
    async def test_preprocessing_cache(self, server):
        """Test query preprocessing cache."""
        # Create identical queries
        vector = np.random.binomial(1, 0.01, 1000).astype(np.uint8)

        query1 = {
            "query_id": "query_001",
            "client_id": "client_123",
            "query_vectors": [vector],
            "query_type": "genomic",
            "parameters": {},
        }

        query2 = {
            "query_id": "query_002",
            "client_id": "client_123",
            "query_vectors": [vector],  # Same vector
            "query_type": "genomic",
            "parameters": {},
        }

        # Process first query
        response1 = await server.process_query(query1)

        # Process second query (should hit cache)
        response2 = await server.process_query(query2)

        # Check that preprocessing was used
        assert server.metrics["preprocessing_hits"] > 0

    @pytest.mark.asyncio
    async def test_shard_selection(self, server):
        """Test shard selection based on query parameters."""
        # Query with specific regions
        shards = server._select_target_shards(
            {
                "regions": [
                    {"chromosome": "chr1", "position": 1000000},
                    {"chromosome": "chr2", "position": 5000000},
                ]
            }
        )

        # Should select chr1 shard
        assert len(shards) >= 1
        assert any(s.shard_id == "genomic_chr1" for s in shards)

    @pytest.mark.asyncio
    async def test_server_status(self, server):
        """Test server status reporting."""
        # Process a few queries first
        for i in range(5):
            query = {
                "query_id": "query_{i}",
                "client_id": "client_123",
                "query_vectors": [np.zeros(100, dtype=np.uint8)],
                "query_type": "genomic",
                "parameters": {},
            }
            await server.process_query(query)

        # Get status
        status = await server.get_server_status()

        assert status["server_id"] == "test_server"
        assert status["server_type"] == "LN"
        assert status["status"] == "healthy"
        assert status["performance"]["total_queries"] == 5
        assert "average_query_time_ms" in status["performance"]
        assert "shards" in status
        assert "resources" in status


class TestGenomicRegion:
    """Test genomic region data structure."""

    def test_serialization(self):
        """Test genomic region serialization."""
        region = GenomicRegion(
            chromosome="chr1",
            start=1000000,
            end=1001000,
            reference_allele="A",
            alternate_alleles=["T", "G"],
            population_frequencies={"AFR": 0.1, "EUR": 0.05},
            annotations={"gene": "BRCA1", "impact": "HIGH"},
        )

        # Serialize
        data = region.to_bytes()
        assert isinstance(data, bytes)
        assert len(data) > 0

        # Deserialize
        region2 = GenomicRegion.from_bytes(data)
        assert region2.chromosome == region.chromosome
        assert region2.start == region.start
        assert region2.alternate_alleles == region.alternate_alleles
        assert region2.population_frequencies == region.population_frequencies


class TestTrustedSignatoryServer:
    """Test HIPAA-compliant trusted signatory server."""

    def test_hipaa_verification(self, tmp_path):
        """Test HIPAA compliance verification."""
        server = TrustedSignatoryServer(
            server_id="ts_001",
            data_directory=tmp_path,
            npi="1234567890",
            baa_hash="a" * 64,
            risk_analysis_hash="b" * 64,
            hsm_serial="HSM123456",
        )

        compliance = server.verify_hipaa_compliance()

        assert compliance["npi_valid"]
        assert compliance["baa_current"]
        assert compliance["risk_analysis_current"]
        assert compliance["audit_enabled"]
        assert compliance["encryption_enabled"]


class TestPIRIntegration:
    """Integration tests for PIR system."""

    @pytest.mark.asyncio
    async def test_multi_server_query(self, tmp_path):
        """Test querying across multiple servers."""
        # Create multiple servers
        servers = []
        for i in range(3):
            server_dir = tmp_path / "server_{i}"
            server_dir.mkdir()

            # Create manifest
            manifest = {
                "shards": [
                    {
                        "id": "shard_{i}",
                        "data_file": "data.dat",
                        "index_file": "data.idx",
                        "size": 1000,
                        "item_count": 100,
                        "data_type": "genomic",
                        "version": "1.0",
                        "checksum": "",
                        "chromosome_ranges": {"chr1": [i * 1000000, (i + 1) * 1000000]},
                    }
                ]
            }

            with open(server_dir / "enhanced_manifest.json", "w") as f:
                json.dump(manifest, f)

            (server_dir / "data.dat").touch()
            (server_dir / "data.idx").touch()

            server = EnhancedPIRServer(
                server_id="server_{i}",
                data_directory=server_dir,
                is_trusted_signatory=(i == 0),  # First server is TS
            )
            servers.append(server)

        # Simulate client creating distributed query
        query_vectors = [
            np.random.binomial(1, 0.001, 100).astype(np.uint8) for _ in range(3)
        ]

        # Each server processes its part
        responses = []
        for i, server in enumerate(servers):
            query = {
                "query_id": "distributed_query_{i}",
                "client_id": "client_456",
                "query_vectors": [query_vectors[i]],
                "query_type": "genomic",
                "parameters": {},
            }
            response = await server.process_query(query)
            responses.append(response)

        # Verify all responses received
        assert len(responses) == 3
        assert all("results" in r for r in responses)

        # Check server types
        assert responses[0]["server_type"] == "TS"
        assert responses[1]["server_type"] == "LN"
        assert responses[2]["server_type"] == "LN"

        # Cleanup
        for server in servers:
            await server.shutdown()

    @pytest.mark.asyncio
    async def test_privacy_preservation(self, tmp_path):
        """Test that server learns nothing from queries."""
        server = EnhancedPIRServer(server_id="privacy_test", data_directory=tmp_path)

        # Create two different queries that should look identical to server
        vector1 = np.zeros(1000, dtype=np.uint8)
        vector1[100] = 1  # Select position 100

        vector2 = np.zeros(1000, dtype=np.uint8)
        vector2[500] = 1  # Select position 500

        query1 = {
            "query_id": "q1",
            "client_id": "client",
            "query_vectors": [vector1],
            "query_type": "genomic",
            "parameters": {},
        }

        query2 = {
            "query_id": "q2",
            "client_id": "client",
            "query_vectors": [vector2],
            "query_type": "genomic",
            "parameters": {},
        }

        # Process both queries
        response1 = await server.process_query(query1)
        response2 = await server.process_query(query2)

        # Server should not be able to distinguish between queries
        # Both should have similar processing times
        time1 = response1["processing_time_ms"]
        time2 = response2["processing_time_ms"]
        assert abs(time1 - time2) < 100  # Within 100ms

        await server.shutdown()


class TestPIRPerformance:
    """Performance tests for PIR system."""

    @pytest.mark.asyncio
    async def test_query_performance(self, tmp_path):
        """Test query processing performance."""
        server = EnhancedPIRServer(
            server_id="perf_test",
            data_directory=tmp_path,
            enable_preprocessing=True,
            cache_size_mb=256,
        )

        # Generate varying query sizes
        query_sizes = [100, 1000, 10000]
        results = {}

        for size in query_sizes:
            vector = np.random.binomial(1, 0.001, size).astype(np.uint8)

            query = {
                "query_id": "perf_{size}",
                "client_id": "perf_client",
                "query_vectors": [vector],
                "query_type": "genomic",
                "parameters": {},
            }

            response = await server.process_query(query)
            results[size] = response["processing_time_ms"]

        # Verify reasonable performance scaling
        # Time should not scale linearly with size due to optimizations
        assert results[10000] < results[100] * 100

        await server.shutdown()

    @pytest.mark.asyncio
    async def test_batch_processing(self, tmp_path):
        """Test batch query processing."""
        server = EnhancedPIRServer(server_id="batch_test", data_directory=tmp_path)

        # Create batch of queries
        batch_size = 10
        queries = []

        for i in range(batch_size):
            vector = np.random.binomial(1, 0.001, 1000).astype(np.uint8)
            query = {
                "query_id": "batch_{i}",
                "client_id": "batch_client",
                "query_vectors": [vector],
                "query_type": "genomic",
                "parameters": {},
            }
            queries.append(query)

        # Process batch
        start_time = asyncio.get_event_loop().time()

        tasks = [server.process_query(q) for q in queries]
        responses = await asyncio.gather(*tasks)

        total_time = asyncio.get_event_loop().time() - start_time

        # Verify all processed
        assert len(responses) == batch_size
        assert all(r.get("query_id").startswith("batch_") for r in responses)

        # Check that batch processing is efficient
        avg_time_per_query = total_time / batch_size
        individual_times = [r["processing_time_ms"] / 1000 for r in responses]

        # Batch should be more efficient than sequential
        assert avg_time_per_query < max(individual_times)

        await server.shutdown()


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])

