# GenomeVault

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-green.svg)](https://opensource.org/licenses/Apache-2.0)

A privacy-preserving genomic data platform using hyperdimensional computing for secure analysis and collaboration.

## üéØ Project Goal

GenomeVault explores how hyperdimensional computing (HDC) and zero-knowledge proofs can enable genomic data analysis while preserving privacy. This is an experimental implementation demonstrating these concepts.

## üî¨ What It Does

GenomeVault provides:

1. **Hyperdimensional Encoding** - Transforms genomic data into high-dimensional vectors (5,000-20,000 dimensions) that preserve similarity relationships while preventing reconstruction of the original data.

2. **Privacy-Preserving Analysis** - Enables similarity comparisons and pattern matching on encoded data without exposing the underlying genomic sequences.

3. **Multi-Modal Integration** - Supports combining different types of biological data (genomic, transcriptomic, clinical) through hypervector binding operations.

## üõ†Ô∏è Current Implementation

### Core Components

- **HDC Encoder** (`hypervector_transform/`) - Implements hyperdimensional encoding with multiple compression tiers
- **Zero-Knowledge Proofs** (`zk_proofs/`) - Basic SNARK and STARK proof systems for genomic assertions
- **PIR System** (`pir/`) - Private information retrieval for querying genomic databases
- **API Layer** (`api/`) - REST endpoints for encoding and analysis operations

### Supported Features

- ‚úÖ Hyperdimensional encoding of genomic features
- ‚úÖ Multiple compression tiers (Mini: 25KB, Clinical: 300KB, Full: 200KB)
- ‚úÖ Similarity computation between encoded vectors
- ‚úÖ Multi-modal data binding (genomic + clinical)
- ‚úÖ Basic zero-knowledge proof generation
- ‚úÖ REST API for encoding operations

### In Development

- üöß Recursive SNARK composition
- üöß Advanced PIR with information-theoretic security
- üöß Federated learning framework
- üöß Clinical validation studies
- üöß Performance optimizations

## üì¶ Installation

```bash
# Clone the repository
git clone https://github.com/rohanvinaik/GenomeVault.git
cd genomevault

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install in development mode
pip install -e .
```

## üöÄ Quick Start

### Basic HDC Encoding

```python
from genomevault.hypervector_transform import create_encoder, OmicsType

# Create encoder with clinical-tier compression
encoder = create_encoder(dimension=10000, compression_tier="clinical")

# Encode genomic features
features = {
    "variants": [1, 0, 1, 1, 0],  # Binary variant presence
    "gene_expression": [0.5, 1.2, 0.8, 2.1]  # Expression levels
}
hypervector = encoder.encode(features, OmicsType.GENOMIC)

print(f"Encoded to {len(hypervector)} dimensions")
```

### Computing Similarity

```python
# Encode two genomic profiles
hv1 = encoder.encode(features1, OmicsType.GENOMIC)
hv2 = encoder.encode(features2, OmicsType.GENOMIC)

# Compute similarity (cosine distance)
similarity = encoder.similarity(hv1, hv2)
print(f"Similarity: {similarity:.3f}")  # Range: -1 to 1
```

### Multi-Modal Binding

```python
from genomevault.hypervector_transform import HypervectorBinder, BindingType

# Create binder
binder = HypervectorBinder(dimension=10000)

# Encode different modalities
genomic_hv = encoder.encode(genomic_data, OmicsType.GENOMIC)
clinical_hv = encoder.encode(clinical_data, OmicsType.CLINICAL)

# Combine modalities
combined = binder.bind([genomic_hv, clinical_hv], BindingType.MULTIPLY)
```

## üèóÔ∏è Architecture

```
genomevault/
‚îú‚îÄ‚îÄ hypervector_transform/   # HDC encoding implementation
‚îÇ   ‚îú‚îÄ‚îÄ hdc_encoder.py      # Main encoding engine
‚îÇ   ‚îú‚îÄ‚îÄ binding_operations.py # Vector binding operations
‚îÇ   ‚îî‚îÄ‚îÄ registry.py         # Version management
‚îú‚îÄ‚îÄ zk_proofs/              # Zero-knowledge proof systems
‚îÇ   ‚îú‚îÄ‚îÄ snark_prover.py     # SNARK implementation
‚îÇ   ‚îî‚îÄ‚îÄ stark_prover.py     # STARK implementation
‚îú‚îÄ‚îÄ pir/                    # Private information retrieval
‚îú‚îÄ‚îÄ api/                    # REST API endpoints
‚îú‚îÄ‚îÄ clinical/               # Clinical integration (WIP)
‚îî‚îÄ‚îÄ tests/                  # Test suite
```

## üß™ Testing

```bash
# Run all tests
pytest

# Run specific test suites
pytest tests/test_hdc_implementation.py -v
pytest tests/test_zk_proofs.py -v

# Run with coverage
pytest --cov=genomevault --cov-report=html
```

## üìä Performance Benchmarks

Based on comprehensive benchmarking suite (`scripts/bench_hdc.py`, `scripts/bench_pir.py`):

### Hyperdimensional Computing (HDC) Performance

**Encoding Throughput** (operations/second):
| Dimension | 100 features | 1000 features | 5000 features |
|-----------|--------------|---------------|---------------|
| 5,000D    | ~1000 ops/s  | ~200 ops/s    | ~50 ops/s     |
| 10,000D   | ~500 ops/s   | ~100 ops/s    | ~25 ops/s     |
| 20,000D   | ~250 ops/s   | ~50 ops/s     | ~12 ops/s     |

**Memory Usage by Compression Tier**:
| Tier | Dimension | Memory | Compression Ratio |
|------|-----------|--------|-------------------|
| Mini | 5,000D | ~25 KB | 100-500x |
| Clinical | 10,000D | ~300 KB | 10-100x |
| Full | 20,000D | ~200 KB | 15-150x |

**Binding Operations** (10,000D vectors):
| Operation | Throughput | Notes |
|-----------|------------|-------|
| Multiply | ~5000 ops/s | Element-wise, commutative |
| Circular | ~1000 ops/s | Convolution, invertible |
| XOR | ~8000 ops/s | Binary, fast |
| Fourier (HRR) | ~500 ops/s | Complex, highest accuracy |

**Similarity Computation**:
| Metric | 10,000D | 20,000D |
|--------|---------|---------|
| Cosine | ~10,000 ops/s | ~5,000 ops/s |
| Euclidean | ~8,000 ops/s | ~4,000 ops/s |
| Hamming | ~12,000 ops/s | ~6,000 ops/s |

**Batch Processing Scalability**:
| Batch Size | Speedup | Efficiency |
|------------|---------|------------|
| 1 | 1.0x | 100% |
| 10 | 8.5x | 85% |
| 50 | 35x | 70% |
| 100 | 60x | 60% |

### Private Information Retrieval (PIR) Performance

**Query Generation**:
| Database Size | Queries/sec | Latency |
|---------------|-------------|---------|
| 1,000 items | ~1000 | ~1ms |
| 10,000 items | ~800 | ~1.25ms |
| 100,000 items | ~500 | ~2ms |
| 1M items | ~200 | ~5ms |

**End-to-End PIR Latency**:
| DB Size | 2 servers | 3 servers | 5 servers |
|---------|-----------|-----------|-----------|
| 1,000 | ~50ms | ~75ms | ~125ms |
| 10,000 | ~100ms | ~150ms | ~250ms |
| 100,000 | ~200ms | ~300ms | ~500ms |

**Batch PIR Performance** (100k database):
| Batch Size | Items/sec | Total Time |
|------------|-----------|------------|
| 10 | ~100 | ~100ms |
| 50 | ~250 | ~200ms |
| 100 | ~400 | ~250ms |
| 500 | ~1000 | ~500ms |

### Zero-Knowledge Proofs Performance

**Expected Performance** (based on implementation):
| Proof System | Generation | Verification | Proof Size |
|--------------|------------|--------------|------------|
| SNARK (Groth16) | ~1-2s | ~25-30ms | ~200 bytes |
| STARK | ~2-5s | ~50-100ms | ~45 KB |
| Recursive SNARK | ~5-10s | ~25ms | ~400 bytes |

### Multi-Modal Pipeline

**Complete Multi-Modal Encoding** (4 modalities):
- Total pipeline time: ~50-100ms
- Individual modality encoding: ~10-25ms each
- Binding operations: ~5-10ms
- Final dimension: 10,000D

### System Requirements

**Minimum Hardware**:
- CPU: 4 cores @ 2.4GHz
- RAM: 8GB
- Storage: 1GB for codebase + data

**Recommended Hardware**:
- CPU: 8+ cores @ 3.0GHz+
- RAM: 16GB+
- GPU: Optional (CUDA 11.8+ for acceleration)
- Storage: SSD with 10GB+ free space

## ‚ö†Ô∏è Limitations & Disclaimers

**This is a research prototype and should not be used for actual clinical or diagnostic purposes.**

Current limitations:
- No clinical validation has been performed
- Performance not optimized for production use
- Security properties not formally verified
- Limited to demonstration datasets
- No regulatory compliance (HIPAA, GDPR) implementation

## üî¨ Technical Background

GenomeVault builds on several research areas:

1. **Hyperdimensional Computing** - Using high-dimensional random projections to create privacy-preserving representations
2. **Zero-Knowledge Proofs** - Cryptographic proofs that reveal nothing beyond the validity of a statement
3. **Private Information Retrieval** - Querying databases without revealing which records are accessed

See the `docs/` directory for detailed technical documentation.

## ü§ù Contributing

This is an active research project. Contributions are welcome in the following areas:

- Performance optimizations
- Additional encoding schemes
- Security analysis
- Test coverage improvements
- Documentation

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## üìö References

Key papers this implementation is based on:

1. Kanerva, P. (2009). "Hyperdimensional computing: An introduction to computing in distributed representation"
2. Gabizon, A. et al. (2019). "PLONK: Permutations over Lagrange-bases for Oecumenical Noninteractive arguments of Knowledge"
3. Ben-Sasson, E. et al. (2018). "Scalable, transparent, and post-quantum secure computational integrity"

## üìÑ License

Apache License 2.0 - see [LICENSE](LICENSE) for details.

## üöß Status

**This is an experimental research project.** While the core HDC encoding and basic proof systems are functional, many features are still in development. The codebase is actively evolving and APIs may change.

For questions or discussions about the research, please open an issue on GitHub.

## üìà Performance Characteristics

### Scalability
- **Linear scaling** with feature size for encoding
- **Constant time** similarity computation regardless of original data size
- **Logarithmic scaling** for batch operations up to ~100 items
- **Memory-efficient** sparse projections available for large dimensions

### Trade-offs
- **Dimension vs Accuracy**: Higher dimensions preserve more information but require more memory/compute
- **Compression vs Quality**: Aggressive compression (Mini tier) trades accuracy for size
- **Batch vs Latency**: Larger batches improve throughput but increase latency
- **Privacy vs Performance**: Stronger privacy guarantees (more servers) increase latency

### Optimization Tips
1. **Use appropriate tier**: Mini for screening, Clinical for analysis, Full for research
2. **Batch operations**: Process multiple samples together for better throughput
3. **Cache projections**: Reuse projection matrices across encodings
4. **Profile your workload**: Use `scripts/bench_hdc.py` to test on your data

---

*GenomeVault is a research exploration into privacy-preserving genomic computation. It is not intended for clinical use.*