"""
Enhanced KAN-HD Hybrid Encoder

Implements the complete hybrid architecture that combines:
- Kolmogorov-Arnold Networks (KAN) for compression
- Hyperdimensional computing for privacy
- Federated learning capabilities
- Scientific interpretability
- Hierarchical multi-modal encoding
"""

import time
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple, Union

import numpy as np
import torch
import torch.nn as nn

from ..encoding.genomic import GenomicEncoder
from .compression import AdaptiveKANCompressor, KANCompressor
from .federated_kan import FederatedKANCoordinator, FederatedKANParticipant
from .hierarchical_encoding import (
    DataModality,
    EncodingSpecification,
    HierarchicalHypervectorEncoder,
    MultiResolutionVector,
)
from .kan_layer import KANLayer, LinearKAN


class EncodingLevel(Enum):
    """Hierarchical encoding levels"""

    BASE = "base"  # 10,000D - Genomic variants
    MID = "mid"  # 15,000D - Expression data
    HIGH = "high"  # 20,000D - Epigenetic data
    FULL = "full"  # All levels combined


class CompressionStrategy(Enum):
    """Compression strategies available"""

    ADAPTIVE = "adaptive"  # Automatically select based on data complexity
    FIXED = "fixed"  # Use fixed compression ratio
    OPTIMAL = "optimal"  # Optimize for best quality/compression tradeoff
    FEDERATED = "federated"  # Optimized for federated learning


class EnhancedKANHybridEncoder(nn.Module):
    """
    Enhanced KAN-HD Hybrid Encoder integrating all insights

    Features:
    1. Adaptive compression with 10-100x ratios
    2. Hierarchical multi-modal encoding
    3. Federated learning support
    4. Scientific interpretability
    5. Privacy-preserving transformations
    6. Real-time performance tuning
    """

    def __init__(
        self,
        base_dim: int = 10000,
        compressed_dim: int = 100,
        enable_federated: bool = False,
        enable_interpretability: bool = True,
        compression_strategy: CompressionStrategy = CompressionStrategy.ADAPTIVE,
    ):
        super().__init__()

        # Core parameters
        self.base_dim = base_dim
        self.compressed_dim = compressed_dim
        self.enable_federated = enable_federated
        self.enable_interpretability = enable_interpretability
        self.compression_strategy = compression_strategy

        # Core HD encoder for genomic data
        self.hd_encoder = GenomicEncoder(dimension=base_dim)

        # Hierarchical encoder for multi-modal data
        self.hierarchical_encoder = HierarchicalHypervectorEncoder(
            base_dim=base_dim, enable_adaptive_dim=True
        )

        # Adaptive KAN compressor based on insights
        self.adaptive_compressor = AdaptiveKANCompressor(input_dim=base_dim)

        # Fixed KAN compressor for fallback
        self.fixed_compressor = KANCompressor(
            input_dim=base_dim, compressed_dim=compressed_dim, num_layers=3
        )

        # Domain-specific projections (learnable Ï†_{q,p} functions)
        self.domain_projections = nn.ModuleDict(
            {
                "genomic_variants": self._create_kan_projection(base_dim, base_dim),
                "oncology": self._create_kan_projection(base_dim, base_dim),
                "rare_disease": self._create_kan_projection(base_dim, 15000),
                "population_genetics": self._create_kan_projection(base_dim, 20000),
                "structural_biology": self._create_kan_projection(base_dim, 25000),
            }
        )

        # Privacy-preserving transformation layers
        self.privacy_layers = nn.ModuleDict(
            {
                "mixer": self._create_privacy_mixer(),
                "noise_generator": self._create_noise_generator(),
                "obfuscator": self._create_obfuscator(),
            }
        )

        # Federated learning components (optional)
        if enable_federated:
            self.federated_coordinator = None  # Will be set when needed
            self.federated_participant = None  # Will be set when needed

        # Interpretability components
        if enable_interpretability:
            self.interpretability_extractor = LinearKAN(base_dim, 128)
            self.pattern_analyzer = nn.Sequential(
                LinearKAN(base_dim, 256), nn.Tanh(), LinearKAN(256, 64), nn.Sigmoid()
            )

        # Performance tracking
        self.performance_history = []
        self.compression_statistics = {}

    def _create_kan_projection(self, in_dim: int, out_dim: int) -> nn.Module:
        """Create KAN-based domain projection"""
        if in_dim == out_dim:
            # Identity projection with learnable KAN transformation
            return nn.Sequential(
                LinearKAN(in_dim, in_dim),
                nn.LayerNorm(in_dim),
                LinearKAN(in_dim, out_dim),
                nn.Tanh(),
            )
        else:
            # Dimensional transformation
            mid_dim = (in_dim + out_dim) // 2
            return nn.Sequential(
                LinearKAN(in_dim, mid_dim),
                nn.LayerNorm(mid_dim),
                LinearKAN(mid_dim, out_dim),
                nn.Tanh(),
            )

    def _create_privacy_mixer(self) -> nn.Module:
        """Create privacy-preserving mixer using KAN layers"""
        return nn.Sequential(
            LinearKAN(self.compressed_dim, self.compressed_dim * 2),
            nn.GELU(),
            nn.Dropout(0.1),
            LinearKAN(self.compressed_dim * 2, self.compressed_dim),
            nn.Tanh(),
        )

    def _create_noise_generator(self) -> nn.Module:
        """Create structured noise generator for differential privacy"""
        return nn.Sequential(LinearKAN(self.compressed_dim, self.compressed_dim), nn.Tanh())

    def _create_obfuscator(self) -> nn.Module:
        """Create obfuscation layer"""
        return nn.Sequential(LinearKAN(self.compressed_dim, self.compressed_dim), nn.Sigmoid())

    def encode_genomic_data(
        self,
        variants: List[Dict],
        compression_ratio: Optional[float] = None,
        privacy_level: str = "sensitive",
    ) -> torch.Tensor:
        """
        Enhanced genomic data encoding with KAN-HD hybrid approach

        Args:
            variants: List of genomic variant dictionaries
            compression_ratio: Target compression ratio (None for adaptive)
            privacy_level: Privacy level ('public', 'sensitive', 'highly_sensitive')

        Returns:
            Compressed and privacy-preserved representation
        """
        start_time = time.time()

        # Step 1: Encode variants to hypervectors
        hd_vector = self.hd_encoder.encode_genome(variants)

        # Step 2: Apply adaptive compression based on strategy
        if self.compression_strategy == CompressionStrategy.ADAPTIVE:
            compressed, compression_level = self.adaptive_compressor.encode(hd_vector.unsqueeze(0))
            self.last_compression_level = compression_level
            achieved_ratio = self._estimate_compression_ratio(hd_vector, compressed)

        elif self.compression_strategy == CompressionStrategy.FIXED:
            compressed = self.fixed_compressor.encode(hd_vector.unsqueeze(0))
            achieved_ratio = self.base_dim / self.compressed_dim
            self.last_compression_level = "fixed"

        elif self.compression_strategy == CompressionStrategy.OPTIMAL:
            # Try both compressors and select best
            adaptive_result, level = self.adaptive_compressor.encode(hd_vector.unsqueeze(0))
            fixed_result = self.fixed_compressor.encode(hd_vector.unsqueeze(0))

            # Choose based on quality metrics
            adaptive_quality = self._compute_quality_score(hd_vector, adaptive_result)
            fixed_quality = self._compute_quality_score(hd_vector, fixed_result)

            if adaptive_quality > fixed_quality:
                compressed = adaptive_result
                self.last_compression_level = level
                achieved_ratio = self._estimate_compression_ratio(hd_vector, compressed)
            else:
                compressed = fixed_result
                self.last_compression_level = "fixed"
                achieved_ratio = self.base_dim / self.compressed_dim

        else:  # FEDERATED
            # Use adaptive but with federated-optimized settings
            compressed, compression_level = self.adaptive_compressor.encode(hd_vector.unsqueeze(0))
            self.last_compression_level = f"federated_{compression_level}"
            achieved_ratio = self._estimate_compression_ratio(hd_vector, compressed)

        compressed = compressed.squeeze(0)

        # Step 3: Apply privacy transformations based on level
        private_compressed = self._apply_privacy_transformations(compressed, privacy_level)

        # Step 4: Update performance statistics
        encoding_time = (time.time() - start_time) * 1000
        self._update_performance_stats(
            encoding_time=encoding_time,
            compression_ratio=achieved_ratio,
            privacy_level=privacy_level,
            data_size=len(variants),
        )

        return private_compressed

    def encode_multimodal_data(
        self,
        data_dict: Dict[str, Union[List[Dict], torch.Tensor]],
        specifications: Dict[str, EncodingSpecification],
    ) -> Dict[str, MultiResolutionVector]:
        """
        Encode multi-modal genomic data with hierarchical resolution

        Args:
            data_dict: Dictionary mapping modality names to data
            specifications: Encoding specifications for each modality

        Returns:
            Dictionary of multi-resolution vectors
        """
        # Convert data to tensors where needed
        tensor_dict = {}
        for modality_name, data in data_dict.items():
            if isinstance(data, list):
                # Genomic variants - convert to hypervectors first
                if modality_name == "genomic_variants":
                    hv = self.hd_encoder.encode_genome(data)
                    tensor_dict[modality_name] = hv
                else:
                    # Other list data - create mock tensor
                    tensor_dict[modality_name] = torch.randn(len(data), 1000)
            else:
                tensor_dict[modality_name] = data

        # Use hierarchical encoder
        return self.hierarchical_encoder.encode_multimodal_data(tensor_dict, specifications)

    def bind_modalities(
        self,
        multi_res_vectors: Dict[str, MultiResolutionVector],
        binding_strategy: str = "hierarchical",
    ) -> MultiResolutionVector:
        """Bind multiple modalities into unified representation"""
        return self.hierarchical_encoder.bind_multimodal_vectors(
            multi_res_vectors, binding_strategy
        )

    def _apply_privacy_transformations(
        self, compressed: torch.Tensor, privacy_level: str
    ) -> torch.Tensor:
        """Apply privacy transformations based on level"""
        result = compressed

        if privacy_level == "public":
            # Minimal privacy transformation
            result = self.privacy_layers["mixer"](result.unsqueeze(0)).squeeze(0)

        elif privacy_level == "sensitive":
            # Standard privacy protection
            mixed = self.privacy_layers["mixer"](result.unsqueeze(0)).squeeze(0)
            noise = self.privacy_layers["noise_generator"](mixed.unsqueeze(0)).squeeze(0)
            result = mixed + 0.01 * noise  # Small amount of structured noise

        elif privacy_level == "highly_sensitive":
            # Maximum privacy protection
            mixed = self.privacy_layers["mixer"](result.unsqueeze(0)).squeeze(0)
            noise = self.privacy_layers["noise_generator"](mixed.unsqueeze(0)).squeeze(0)
            obfuscated = self.privacy_layers["obfuscator"](mixed.unsqueeze(0)).squeeze(0)

            # Combine with more noise and obfuscation
            result = obfuscated + 0.05 * noise

        return result

    def _estimate_compression_ratio(
        self, original: torch.Tensor, compressed: torch.Tensor
    ) -> float:
        """Estimate achieved compression ratio"""
        original_bits = original.numel() * 32  # Assuming float32
        compressed_bits = compressed.numel() * 32
        return original_bits / compressed_bits

    def _compute_quality_score(self, original: torch.Tensor, compressed: torch.Tensor) -> float:
        """Compute quality score for compression"""
        # Reconstruct and compare
        try:
            if hasattr(self.adaptive_compressor, "decode"):
                reconstructed = self.adaptive_compressor.decode(
                    compressed, self.last_compression_level
                )
            else:
                reconstructed = self.fixed_compressor.decode(compressed)

            # Compute similarity metrics
            mse = torch.mean((original - reconstructed.squeeze(0)) ** 2).item()
            cosine_sim = torch.cosine_similarity(original.unsqueeze(0), reconstructed).item()

            # Combined quality score (higher is better)
            quality = cosine_sim / (1 + mse)
            return quality

        except Exception:
            return 0.5  # Default score if reconstruction fails

    def _update_performance_stats(
        self, encoding_time: float, compression_ratio: float, privacy_level: str, data_size: int
    ):
        """Update performance statistics"""
        stats = {
            "timestamp": time.time(),
            "encoding_time_ms": encoding_time,
            "compression_ratio": compression_ratio,
            "privacy_level": privacy_level,
            "data_size": data_size,
            "strategy": self.compression_strategy.value,
        }

        self.performance_history.append(stats)

        # Update aggregated statistics
        if privacy_level not in self.compression_statistics:
            self.compression_statistics[privacy_level] = {
                "count": 0,
                "avg_time": 0.0,
                "avg_ratio": 0.0,
                "avg_size": 0.0,
            }

        stat = self.compression_statistics[privacy_level]
        stat["count"] += 1
        stat["avg_time"] = (stat["avg_time"] * (stat["count"] - 1) + encoding_time) / stat["count"]
        stat["avg_ratio"] = (stat["avg_ratio"] * (stat["count"] - 1) + compression_ratio) / stat[
            "count"
        ]
        stat["avg_size"] = (stat["avg_size"] * (stat["count"] - 1) + data_size) / stat["count"]

    def decode_compressed_data(
        self, compressed: torch.Tensor, compression_level: Optional[str] = None
    ) -> torch.Tensor:
        """
        Decode compressed representation back to hypervector space

        Args:
            compressed: Compressed representation
            compression_level: Compression level used (for adaptive compressor)

        Returns:
            Reconstructed hypervector
        """
        level = compression_level or getattr(self, "last_compression_level", "default")

        compressed_batch = compressed.unsqueeze(0)

        if level.startswith("federated_"):
            actual_level = level.replace("federated_", "")
            reconstructed = self.adaptive_compressor.decode(compressed_batch, actual_level)
        elif level == "fixed":
            reconstructed = self.fixed_compressor.decode(compressed_batch)
        elif hasattr(self.adaptive_compressor, "decode"):
            reconstructed = self.adaptive_compressor.decode(compressed_batch, level)
        else:
            reconstructed = self.fixed_compressor.decode(compressed_batch)

        return reconstructed.squeeze(0)

    def extract_scientific_patterns(self, data: torch.Tensor) -> Dict[str, Any]:
        """
        Extract scientifically interpretable patterns

        Args:
            data: Input data tensor

        Returns:
            Dictionary of discovered patterns and insights
        """
        if not self.enable_interpretability:
            return {}

        # Extract interpretable features
        interpretable_features = self.interpretability_extractor(data.unsqueeze(0)).squeeze(0)

        # Analyze patterns
        pattern_scores = self.pattern_analyzer(data.unsqueeze(0)).squeeze(0)

        # Find dominant patterns
        dominant_patterns = torch.argsort(pattern_scores, descending=True)[:10]

        # Extract frequency analysis
        fft_analysis = torch.fft.fft(data.float())
        dominant_frequencies = torch.argsort(torch.abs(fft_analysis), descending=True)[:5]

        # Compute sparsity and other interpretability metrics
        sparsity = torch.sum(torch.abs(data) < 0.1).item() / data.numel()
        energy_concentration = torch.sum(data**2).item()

        return {
            "interpretable_features": interpretable_features.tolist(),
            "pattern_scores": pattern_scores.tolist(),
            "dominant_patterns": dominant_patterns.tolist(),
            "dominant_frequencies": dominant_frequencies.tolist(),
            "sparsity_ratio": sparsity,
            "energy_concentration": energy_concentration,
            "interpretability_score": torch.mean(pattern_scores).item(),
        }

    def get_performance_summary(self) -> Dict[str, Any]:
        """Get comprehensive performance summary"""
        if not self.performance_history:
            return {}

        recent_history = self.performance_history[-100:]  # Last 100 operations

        avg_encoding_time = np.mean([h["encoding_time_ms"] for h in recent_history])
        avg_compression_ratio = np.mean([h["compression_ratio"] for h in recent_history])

        # Privacy level distribution
        privacy_distribution = {}
        for h in recent_history:
            level = h["privacy_level"]
            privacy_distribution[level] = privacy_distribution.get(level, 0) + 1

        # Strategy effectiveness
        strategy_stats = {}
        for h in recent_history:
            strategy = h["strategy"]
            if strategy not in strategy_stats:
                strategy_stats[strategy] = {"count": 0, "avg_time": 0, "avg_ratio": 0}

            stat = strategy_stats[strategy]
            stat["count"] += 1
            stat["avg_time"] = (
                stat["avg_time"] * (stat["count"] - 1) + h["encoding_time_ms"]
            ) / stat["count"]
            stat["avg_ratio"] = (
                stat["avg_ratio"] * (stat["count"] - 1) + h["compression_ratio"]
            ) / stat["count"]

        return {
            "total_operations": len(self.performance_history),
            "recent_avg_encoding_time_ms": avg_encoding_time,
            "recent_avg_compression_ratio": avg_compression_ratio,
            "privacy_level_distribution": privacy_distribution,
            "strategy_effectiveness": strategy_stats,
            "compression_statistics": self.compression_statistics,
            "current_strategy": self.compression_strategy.value,
            "interpretability_enabled": self.enable_interpretability,
            "federated_enabled": self.enable_federated,
        }

    def tune_performance(
        self,
        target_latency_ms: Optional[float] = None,
        target_compression_ratio: Optional[float] = None,
        target_privacy_level: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Automatically tune performance parameters

        Args:
            target_latency_ms: Target encoding latency
            target_compression_ratio: Target compression ratio
            target_privacy_level: Target privacy level

        Returns:
            Tuning results and recommendations
        """
        recommendations = {}

        # Analyze current performance
        summary = self.get_performance_summary()

        if target_latency_ms and summary:
            current_latency = summary["recent_avg_encoding_time_ms"]
            if current_latency > target_latency_ms:
                # Recommend faster strategy
                if self.compression_strategy != CompressionStrategy.FIXED:
                    recommendations["compression_strategy"] = CompressionStrategy.FIXED
                    recommendations["reason"] = "Switch to fixed compression for lower latency"
            else:
                # Can use higher quality strategy
                if self.compression_strategy != CompressionStrategy.OPTIMAL:
                    recommendations["compression_strategy"] = CompressionStrategy.OPTIMAL
                    recommendations["reason"] = "Switch to optimal compression for better quality"

        if target_compression_ratio and summary:
            current_ratio = summary["recent_avg_compression_ratio"]
            if current_ratio < target_compression_ratio:
                recommendations["increase_compression"] = True
                recommendations["suggested_dim_reduction"] = int(self.compressed_dim * 0.8)

        # Apply recommendations if provided
        if "compression_strategy" in recommendations:
            old_strategy = self.compression_strategy
            self.compression_strategy = recommendations["compression_strategy"]
            recommendations[
                "applied_change"
            ] = f"Changed from {old_strategy.value} to {self.compression_strategy.value}"

        return recommendations

    def enable_federated_mode(
        self, participant_id: str, institution_type: str, is_coordinator: bool = False
    ) -> Dict[str, Any]:
        """
        Enable federated learning mode

        Args:
            participant_id: Unique participant identifier
            institution_type: Type of institution
            is_coordinator: Whether this instance is the coordinator

        Returns:
            Federated setup information
        """
        if not self.enable_federated:
            raise RuntimeError("Federated learning not enabled in constructor")

        if is_coordinator:
            self.federated_coordinator = FederatedKANCoordinator(
                base_dim=self.base_dim, compressed_dim=self.compressed_dim
            )
            return {"role": "coordinator", "status": "ready", "can_accept_participants": True}
        else:
            self.federated_participant = FederatedKANParticipant(
                participant_id=participant_id,
                institution_type=institution_type,
                base_dim=self.base_dim,
                compressed_dim=self.compressed_dim,
            )
            return {
                "role": "participant",
                "participant_id": participant_id,
                "institution_type": institution_type,
                "status": "ready",
            }

    def compute_privacy_guarantee(
        self, original: torch.Tensor, encoded: torch.Tensor
    ) -> Dict[str, float]:
        """
        Compute comprehensive privacy guarantee metrics

        Args:
            original: Original data tensor
            encoded: Encoded/compressed tensor

        Returns:
            Dictionary with privacy metrics
        """
        # Basic privacy metrics
        original_entropy = self._estimate_entropy(original)
        encoded_entropy = self._estimate_entropy(encoded)

        # Mutual information approximation
        information_leakage = self._estimate_mutual_information(original, encoded)

        # Reconstruction attack resistance
        reconstruction_difficulty = self._test_reconstruction_attacks(original, encoded)

        # Correlation analysis
        correlation = self._compute_correlation(original, encoded)

        # Overall privacy score (higher is better)
        privacy_score = (
            reconstruction_difficulty * 0.4
            + (1 - information_leakage) * 0.3
            + (1 - abs(correlation)) * 0.3
        )

        return {
            "information_preservation_ratio": encoded_entropy / (original_entropy + 1e-8),
            "information_leakage": information_leakage,
            "reconstruction_difficulty": reconstruction_difficulty,
            "correlation_magnitude": abs(correlation),
            "privacy_score": privacy_score,
            "entropy_original": original_entropy,
            "entropy_encoded": encoded_entropy,
        }

    def _estimate_entropy(self, tensor: torch.Tensor) -> float:
        """Estimate entropy using histogram method"""
        # Quantize to 256 levels
        tensor_flat = tensor.flatten()
        if tensor_flat.numel() == 0:
            return 0.0

        quantized = torch.floor(
            (tensor_flat - tensor_flat.min()) / (tensor_flat.max() - tensor_flat.min() + 1e-8) * 255
        )

        # Compute histogram
        hist = torch.histc(quantized, bins=256, min=0, max=255)
        hist = hist / hist.sum()  # Normalize

        # Compute entropy
        entropy = -torch.sum(hist * torch.log2(hist + 1e-10))

        return entropy.item()

    def _estimate_mutual_information(self, original: torch.Tensor, encoded: torch.Tensor) -> float:
        """Estimate mutual information between original and encoded data"""
        # Simplified mutual information estimation
        # In practice, would use more sophisticated methods

        # Ensure same size for comparison
        if original.shape != encoded.shape:
            if original.numel() > encoded.numel():
                original = original.flatten()[: encoded.numel()].reshape(encoded.shape)
            else:
                encoded = encoded.flatten()[: original.numel()].reshape(original.shape)

        # Compute joint and marginal entropies
        joint_data = torch.stack([original.flatten(), encoded.flatten()], dim=1)  # noqa: F841

        # Quantize for histogram
        original_q = torch.floor(  # noqa: F841
            (original.flatten() - original.min()) / (original.max() - original.min() + 1e-8) * 15
        )
        encoded_q = torch.floor(  # noqa: F841
            (encoded.flatten() - encoded.min()) / (encoded.max() - encoded.min() + 1e-8) * 15
        )

        # Compute mutual information approximation
        # MI = H(X) + H(Y) - H(X,Y)
        h_original = self._estimate_entropy(original)
        h_encoded = self._estimate_entropy(encoded)

        # Joint entropy (simplified)
        joint_entropy = h_original + h_encoded  # Upper bound

        # Mutual information (approximate)
        mi = h_original + h_encoded - joint_entropy

        # Normalize to [0, 1]
        mi_normalized = mi / (min(h_original, h_encoded) + 1e-8)

        return max(0.0, min(1.0, mi_normalized))

    def _test_reconstruction_attacks(self, original: torch.Tensor, encoded: torch.Tensor) -> float:
        """Test resistance to reconstruction attacks"""
        num_trials = 50
        successful_attacks = 0

        for _ in range(num_trials):
            try:
                # Random linear attack
                if original.numel() <= encoded.numel():
                    attack_matrix = torch.randn(encoded.numel(), original.numel())
                    reconstruction_attempt = torch.matmul(
                        encoded.flatten().unsqueeze(0), attack_matrix
                    ).reshape(original.shape)
                else:
                    # Simple truncation attack
                    reconstruction_attempt = encoded.flatten()[: original.numel()].reshape(
                        original.shape
                    )

                # Check if attack was successful
                similarity = torch.cosine_similarity(
                    original.flatten().unsqueeze(0), reconstruction_attempt.flatten().unsqueeze(0)
                ).item()

                if similarity > 0.8:  # Threshold for successful attack
                    successful_attacks += 1

            except Exception:
                # Attack failed due to dimension mismatch or other error
                continue

        # Return difficulty score (higher is better)
        difficulty = 1.0 - (successful_attacks / num_trials)
        return difficulty

    def _compute_correlation(self, original: torch.Tensor, encoded: torch.Tensor) -> float:
        """Compute correlation between original and encoded data"""
        try:
            if original.shape == encoded.shape:
                correlation = torch.corrcoef(torch.stack([original.flatten(), encoded.flatten()]))[
                    0, 1
                ].item()
            else:
                # Different shapes - use truncated correlation
                min_size = min(original.numel(), encoded.numel())
                orig_flat = original.flatten()[:min_size]
                enc_flat = encoded.flatten()[:min_size]

                correlation = torch.corrcoef(torch.stack([orig_flat, enc_flat]))[0, 1].item()

            return correlation if not torch.isnan(torch.tensor(correlation)) else 0.0

        except Exception:
            return 0.0
